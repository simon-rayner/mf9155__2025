---
title: "miRNA Prediction"
author: "Simon Rayner"
date: '2025-10-19'
output: html_document
---


# 1. Introduction

there are many articles about the unlimited and disruptive potential of statistical learning approaches applied to the sciences and medicine. But, at the same time, there are also some articles warning that incorrectly applied methodology can lead to misleading or incorrect results. We want to take a look at the latter case. However, while there are many examples showing how SL methods can be applied to scientific and medical data, there don't seem to be any examples about how to incorrectly apply a model to a dataset. 

Here, we try to train a SVM to recognise miRNA sequences from a set of training sequences consisting of positive data (human miRNA sequences taken from miRBase v22.1) and negative data (random DNA sequences) and see how the trained model performs.

Before we start with the SVM part, we are also going to do some initial set up of the code

# 2. File Paths

Hard coding file paths in your code doesn't really align with the philosophy of Reproducible Research. As we saw in the Gerstung code, finding every location where a file path is specified is a time consuming and error prone process. So, rather than hard coding file paths throughout the R code I specify them in a separate file and load them as a first step. 

Also, where possible, I define a root folder and build my file paths relative to that folder.

For example, for this course in 2024, I had separate folders for each lecture/lab

```
MF9155_simon_2024
├── lecture1__GerstungPaper
│   ├── code
│   ├── data
│   └── SupplementaryData
├── lecture2__ReproducibleResearch
│   ├── code
│   └── data
├── lecture3__Data_References
│   ├── annotation
│   ├── mapped_reads
│   ├── mapped_reads0
│   ├── mapped_reads1
│   ├── mapped_reads2
│   ├── mappedReadsQ
│   └── ngs_test_data
├── lecture4__Data_Handling
│   ├── extra_stuff
│   ├── miRNA_data_processing_files
│   ├── ngs
│   ├── packages
│   └── TBdata
└── lecture5__GerstungCode
    └── model_fitting

```
I have multiple computers using different operating systems, so when I switch between them, I only need to change the root folder and and all the file paths will be correct.

Similarly, when you download my files, you only need to change the root folder to wherever you downloaded the files and the file path will be correct on your computer.

we will look at this in more detail in section 4.



# 3 Try Catch statements
I use `Try/Catch` statements to try and trap errors in a more graceful manner. This can make it easier for a user to understand what went wrong, rather than trying to figure out a crypic error generated by R.


The basic format of a `Try/Catch` statement is

```
tryCatch(
  expr = { },                 # Code that may throw an error or warning when executed
  warning = function(w) { },  # Code to execute if a warning occurs
  error = function(e) {  },   # Code to execute if an error occurs 
  finally = { }.              # Code to execute regardless of errors or warnings
)
```

So, let's use a `Try/Catch` statement to set the root folder. I need to do this as have multiple computers running different operating systems, and I want a simple way to switch my `rootFolder`

Although I multiple computers, there are only two types of file paths. One for the `MacOS`, and one for `Linux.` 

Under  `MacOS` (the home folder is `/Users/username`) and one for `Linux.` (the home folder is `/home/username`).

So, the code that is executed within the `expr{}` reads the `computer` variable and try 

```{r setComputerName, echo=FALSE}

library(rlang)
library(glue)
library(here)  

paste0("setting root folder...")
computer<-"MacOS"
paste0("..computer is <", computer, ">")

tryCatch(
  expr = {
    rootFolder<-""
    if (computer=="MacOS"){
      rootFolder<-"/Users/simonray/uio_dropbox_sr/myTeaching/MF9155_2025"
    }else{
      if (computer=="Linux"){
        rootFolder<-"/media/simonray/data24/data/uio_dropbox_sr/myTeaching/MF9155_2025"
      }else{
        paste0("Unknown computer name <", computer, ">")
        rlang::abort("Unknown computer name <" + computer + ">")
      } 
    }
    paste0("...set root folder to <", rootFolder, ">")
  },
  warning = function(w) { print(paste0("...got unknown warning<",w,">")) },# Code to execute if a warning occurs
  error = function(e) { rlang::abort(paste0("...Error: user specified an unknown computer type <",e, "> Aborting")) },# Code to execute if an error occurs 
  finally = {paste("...finished") }# Code to execute regardless of errors or warnings
)

```

Now i have set the `rootFolder` i can load my file paths. 

We add another  `Try/Catch` statement as loading files is a common source of errors

```{r loadPaths}

tryCatch(
  expr = {
    paste0("Loading file paths file <", here(rootFolder, "SRCommonPaths.R"), ">")
    source(here(rootFolder, "SRCommonPaths__2025.R"))
    paste0("...done")
  },
  warning = function(w) { print(paste0("...got unknown warning<",w,">")) },# Code to execute if a warning occurs
  error = function(e) { rlang::abort(paste0("...error loading file: <", e, "> aborting.")) },# Code to execute if an error occurs 
  finally = { }# Code to execute regardless of errors or warnings
)

```



# 4. Logging 

Lastly, we want to add some code to use log files. This allows us write all the program output to a file in a time stamped manner. The output then looks something like this

```
2025-10-29 17:00:09.852169 INFO::loading file paths...
2025-10-29 17:00:09.867056 INFO::downloading reference BED annotionation for chromatin studies
```
The benefit is that you still have the output after the program has finished. This is useful if you are running multiple analyses or running on a remote machine.

There are various libraries to do this. I use the `lgr` library as it attempts to approximate the features of logging packages in other languages.

a simple example using `lgr` is shown in the Rscript `../code/logging_example.R`


I generally create a logfile with a name that contains:

  1. The name of the script that created the logfile (using the `this.path` library)
  2. The time the logfile was created 
  
If you are running different analyses with different R code on different days, this makes it easier finding the relevant logfile. So, following the example in `./logging_example.R`



```{r initLogger}
library(lgr)       #install.packages("lgr")
library(this.path) #install.packages("this.path") 
                   # Need this to get the name of the script that is initiating the logger instance
                   # see the call to `this.path()` below

###############################################################################
# create a logfile with a name that contains the name of the script 
# and the time it was created
###############################################################################
script_name<-tools::file_path_sans_ext(basename(this.path()))
date_time_str <- format(Sys.time(), "%Y-%m-%d__%H-%M-%S")
logfile_folder<-here(rootFolder, mirna_prediction_folder, "log_files")


###############################################################################
# If the logfile folder doesn't exist, create it
###############################################################################
if (!dir.exists(logfile_folder)) {
  dir.create(logfile_folder)
  print(paste("log file folder '", logfile_folder, "' created successfully.", sep = ""))
} else {
  print(paste("log file folder '", logfile_folder, "' already exists.", sep = ""))
}


###############################################################################
# initiate a logger instance
###############################################################################
logfile_name<-here(logfile_folder, paste0(script_name, "__", date_time_str, ".log" ))

mirsvm_logger <- get_logger("mirsvm_logger")
mirsvm_logger$add_appender(lgr::AppenderFile$new(logfile_name), name = "file_appender")
mirsvm_logger$info(sprintf("log file created <%s>", format(Sys.time(), "%Y-%m-%d__%H-%M-%S")))

```

# Loading the project positive training data

We are finally ready to load our data

I have created a training file of human miRNA sequences from [miRBase](https://mirbase.org), which is the most commonly used reference for miRNAs. There are a total of ~2656 human miRNAs in miRBase. However, there are several duplicate sequences (miRNAs with different names but identical sequence). If you remove these, you end up with a set of 2380 unique sequences. I took the first 1500 sequences for my positive training set.


```{r importPosMiRData}
library(tidyverse)
mir_pos_data_path<-here(rootFolder, mirna_prediction_folder, mirna_prediction_positive_training_data)

###############################################################################
# load the file
###############################################################################
tryCatch(
  expr = { 
    mirsvm_logger$info(sprintf("loading miRNA positive data from <%s>", mir_pos_data_path))
    tb_mirna_pos_data<-read_tsv(mir_pos_data_path)
    },
  warning = function(w) { mirsvm_logger$warn(sprintf("got warning %s...", w)) },
  error = function(e) { 
    mirsvm_logger$error(sprintf("got error <%s> ...", e))
    rlang::abort(sprintf("Aborting: couldn't load data. got error <%e>")) },# Code to execute if an error occurs 
  finally = { }# Code to execute regardless of errors or warnings
)
```
It's always a good idea to see what the data looks like and if it matches what we expect

```{r histogram_training_data}

###############################################################################
# Plot a histogram of lengths
###############################################################################
p<-ggplot(data = tb_mirna_pos_data , aes(x = str_length(sequence))) +
     geom_histogram(binwidth = 1, fill = "green", color = "black") +
     scale_x_continuous(breaks = seq(15, 30, by = 1)) +
     labs(x = "miRNA length", y="count", title = "Distribution of miRNA lengths",
    subtitle = "for positive training data")

```


# Generate the negative training data

Use the `Biostrings` library to generate random sequences. From the histogram, we see that miRNAs are 22nt in length, so choose that for the length 

```{r generate_negative_training_data}
###############################################################################
# Negative data:
#
# We also need a corresponding set of 1500 negative data
# Let's use random sequence. 
# Most miRNAs are 22nt in length, so choose that for the length 
#  of our negative sequences
#
###############################################################################
library(universalmotif) #BiocManager::install(c("universalmotif", "Biostrings"))
library(Biostrings)  

random_rna_sequences <- create_sequences(
  seqnum =1500,
  seqlen = 22,
  alphabet = "RNA",
  freqs = c(A = 0.25, U = 0.25, C = 0.25, G = 0.25)
)

# Convert to a tibble that matches the positive data

names(tb_mirna_pos_data )

tb_neg_data<-as_tibble(list(name = paste0("random_", 1:1500),
                        sequence = as.character(RNAStringSet(random_rna_sequences)),
                        class = rep(0,1500)))
```


Finally, merge the positive and negative data into a single `Tibble`

```{r merge_positive_and_negative_train_data}
tb_train_data_all<-bind_rows(tb_mirna_pos_data , tb_neg_data)


```

# Using the e1079 package
We now have the data we need to train an SVM. But first, let's try out a simple test dataset to familiarise ourselves a little with the `e1079` library

## A simple test of the e1079 package 

Let´s generate some random data built from a normal distribution


```{r genRandomData}
# generate some random data
set.seed(1)
x=matrix(rnorm(20*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
plot(x, col=(3-y))
dat=data.frame(x=x, y=as.factor(y))
dat
```


Now, we use this data to train the model. Here, the plot shows us a linear hyperplane will work well. 

We first try training an SVM with a fixed cost by setting `cost=0,1`

```{r trainRandom}
#BiocManager::install("RBioinf")
library(e1071)
svmfitR=svm(y~., data=dat, kernel="linear", cost=0.1,scale=FALSE)
svmfitR$index
summary(svmfitR)
plot(svmfitR, dat)
svmfitR$index
```

but, we can use the `tune` method to examine a range of costs to find the best performance
```{r trainRandom}
tune.outR <- tune(svm , y~.,  data = dat , kernel = "linear", ranges = list(cost = c(0.001 , 0.01, 0.1, 1, 5, 10, 100)))
#summary(tune.outR)

bestmodR <- tune.outR$best.model
summary(bestmodR)


```


```{r testRandom}
set.seed(1)
xtest=matrix(rnorm(20*2), ncol=2)
ytest=sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,] + 1
testdat=data.frame(x=xtest, y=as.factor(ytest))
ypred=predict(bestmodR,testdat)
table(predict=ypred, truth=testdat$y)

```

The truth table is a simple way to look at how well the model performed. It will be covered more extensively in subsequent lectures. 
Basically, it shows 

* how many negative data points were correctly predicted to be negative (True Negatives/TN), 
* how many negative data points were incorrectly predicted to be positive (False Positives/FP) 
* how many positive data points were correctly predicted to be positive (True Positives/TP)
* how many positive data points were incorrectly predicted to be negative (False Negatives/FN)

```
                        A perfect model         A randomly trained model   A badly trained mode
                                                (random performance)       (labels switched?)
          truth                 truth                      truth                  truth     
predict  -1  1         predict  -1  1              predict  -1  1         predict  -1  1
     -1   TN FP             -1  10  0                   -1   5  5              -1   0  10
      1   FN TP              1   0 10                    1   5  5               1  10   0 
     
```

So, based on this, the trained SVM does pretty well with the supplied training and testing data.


# A miRNA Prediction SVM model

Now we try and do the same thing using miRNA sequences. 



## One Hot Encoding
First of all, we need to have a way of encoding the sequences so they can be used as input to the svm method. To do this, we use one hot encoding.  Each nucleotide is represented by four inputs:

```{r oneHotEncodeFunction}
library(stringr)
library(e1071)

dna <- c("A", "C", "G", "T")

one_hot_encode <- function(x){
  spl <- strsplit(x, "")[[1]]
  fa <- factor(spl, levels = dna)
  sapply(fa, table) |>
    Reduce(f = c, x = _)
}
```


To demonstrate this, we encode a set of short test sequences. 
```{r testOneHotEncode}
library(stringr)

dataIn <- c(
  "AACCGGTT", 
  "TTGGCCAA", 
  "CTTACGTA", 
  "GTACGTCC"
  )


data_in_onehot<-data.frame(do.call(rbind,lapply(dataIn, one_hot_encode)))
print(data_in_onehot)
```

## One Hot Encode the miRNA data
So, now let's one hot encode our training data

```{r loadAndEncodeMiRs}
# one hotencode
encodedTrainSeqsDNA<-data.frame(do.call(rbind,lapply(tb_train_data_all$sequence, one_hot_encode)))

# add classification column
y<-tb_train_data_all$class
encodedTrainSeqsDNA  <-cbind(y,encodedTrainSeqsDNA)

# persuade a list of strings to become a dataframe of doubles
dfEncodedTrainSeqsDNA <- as.data.frame(lapply( encodedTrainSeqsDNA, as.double ))
dfEncodedTrainSeqsDNA$y = as.factor(dfEncodedTrainSeqsDNA$y)
```


## Train and tune the SVM

Now we have one-hot encoded our data, we are ready to train.
We first try a `polynomial` kernel, as it seems unlikely a linear hyperplane will work with this complex dataset

Note: this takes a few minutes to run, so we can also load the trained model from a `.RData` file

```{r loadTrainedSVMPoly}
bestmodMiR<-readRDS(here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR.rds"))
summary(bestmodMiR)

``` 

Otherwise, we can run the training command and 
try different values for cost and take the model with the best overall performance

```{r trainMiRs}
library(e1071)


#svmfitMiR$index
summary(svmfitMiR)
tunedMiR <- tune(svm , y~.,  data = dfEncodedTrainSeqsDNA , kernel = "polynomial", ranges = list(cost = c(0.001 , 0.01, 0.1, 1, 5, 10, 100)))
summary(tunedMiR)

bestmodMiR <- tunedMiR$best.model
summary(bestmodMiR)

# it takes a while to run the training, so we save the trained model
saveRDS(bestmodMiR, file = here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR.rds"))
```

# Testing the trained SVM with some test data
We have found the model that delivers the best performance with the training data. How does it perform with an independent test set?

To investigate this, we will test the trained model against two different test sets


## Test dataset 1
This test data consists of another set of 384 human miRNAs from miRBase that weren't in the training set + 384 more random sequences. 
As above, we load the positive data and generate the negative sequences using the `Biostrings` package


```{r generate_testdata_1}

mir_pos_test_data_path<-here(rootFolder, mirna_prediction_folder, mirna_prediction_positive_test_data)

###############################################################################
# load the file
###############################################################################
tryCatch(
  expr = { 
    mirsvm_logger$info(sprintf("loading miRNA positive test data from <%s>", mir_pos_train_data_path))
    tb_mirna_pos_test_data<-read_tsv(mir_pos_test_data_path)
    },
  warning = function(w) { mirsvm_logger$warn(sprintf("got warning %s...", w)) },
  error = function(e) { 
    mirsvm_logger$error(sprintf("got error %s...", e))
    rlang::abort("Aborting: couldn't load positive test dataset 1.") },# Code to execute if an error occurs 
  finally = { }# Code to execute regardless of errors or warnings
)

no_of_pos_test_seqs<-length(tb_mirna_pos_test_data$sequence)


library(universalmotif) #BiocManager::install(c("universalmotif", "Biostrings"))
library(Biostrings)  
library(tidyverse)

###############################################################################
# Generate some more random sequences
###############################################################################
random_rna_test_sequences <- create_sequences(
  seqnum =no_of_pos_test_seqs,
  seqlen = 22,
  alphabet = "DNA",
  freqs = c(A = 0.25, U = 0.25, C = 0.25, G = 0.25)
)

###############################################################################
# Build the final test datasset as a Tibble
###############################################################################


tb_neg_test_data<-as_tibble(list(name = paste0("random_", 1:no_of_pos_test_seqs),
                        sequence = as.character(RNAStringSet(random_rna_test_sequences)),
                        class = rep(0,no_of_pos_test_seqs)))

tb_mirna_test_data<-bind_rows(tb_mirna_pos_test_data, tb_neg_test_data)

###############################################################################
# one hot encode
###############################################################################

encodedTestSeqsDNA<-data.frame(do.call(rbind,lapply(tb_mirna_test_data$sequence, one_hot_encode)))

# add classification column
y<-tb_mirna_test_data$class
encodedTestSeqsDNA  <-cbind(y,encodedTestSeqsDNA)

# persuade a list of strings to become a dataframe of doubles
df_EncodedTestSeqsDNA <- as.data.frame(lapply( encodedTestSeqsDNA, as.double ))
df_EncodedTestSeqsDNA$y = as.factor(df_EncodedTestSeqsDNA$y)

###############################################################################
# send the test data to the trained model
###############################################################################

yPredMiR<-predict(bestmodMiR , df_EncodedTestSeqsDNA)
table(predict = yPredMiR , truth = df_EncodedTestSeqsDNA$y)

```

The model performance is pretty awful
Why?


#Part 2


```{r oneHotEncodeFunctionRNA}
library(stringr)
library(e1071)

rna <- c("A", "C", "G", "U")

one_hot_encode_RNA <- function(x){
  spl <- strsplit(x, "")[[1]]
  fa <- factor(spl, levels = rna)
  sapply(fa, table) |>
    Reduce(f = c, x = _)
}
```

## Load and encode the training data


```{r loadAndEncodeMiRsAsRNAs}
# one hotencode
encodedTrainSeqsRNA<-data.frame(do.call(rbind,lapply(tb_train_data_all$sequence, one_hot_encode_RNA)))

# add classification column
y<-tb_train_data_all$class
encodedTrainSeqsRNA  <-cbind(y,encodedTrainSeqsRNA)

# persuade a list of strings to become a dataframe of doubles
dfEncodedTrainSeqsRNA <- as.data.frame(lapply( encodedTrainSeqsRNA, as.double ))
dfEncodedTrainSeqsRNA$y = as.factor(dfEncodedTrainSeqsRNA$y)
```

## Train and tune the SVM

Remember: this takes a few minutes to run, so we can also load the trained model from a `.RData` file

```{r loadModel2}
bestmodMiR2<-readRDS(here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR2.rds"))

summary(bestmodMiR2)

``` 

Train the model from the data

```{r trainMiRs2}
library(e1071)
svmfitMiR2=svm(y~., data=dfEncodedTrainSeqsRNA, kernel="polynomial", cost=0.1,scale=FALSE)

#svmfitMiR$index
summary(svmfitMiR)
tunedMiR2 <- tune(svm , y~.,  data = dfEncodedTrainSeqsRNA , kernel = "polynomial", ranges = list(cost = c(0.001 , 0.01, 0.1, 1, 5, 10, 100)))
summary(tunedMiR2)

bestmodMiR2 <- tunedMiR2$best.model
summary(bestmodMiR)

# it takes a while to run the training, so we save the trained model

saveRDS(tunedMiR2, file = here(rootFolder, mirna_prediction_folder, "data", "tunedMiR2.rds"))
saveRDS(bestmodMiR, file = here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR2.rds"))



``` 


## Regenerate the test dataset 1 and test again


```{r testMiRModel2_data11}
# first need to reencode the test daata

###############################################################################
# one hot encode
###############################################################################

encodedTestSeqsRNA<-data.frame(do.call(rbind,lapply(tb_mirna_test_data$sequence, one_hot_encode)))

# add classification column
y<-tb_mirna_test_data$class
encodedTestSeqsRNA  <-cbind(y,encodedTestSeqsRNA)

# persuade a list of strings to become a dataframe of doubles
df_EncodedTestSeqsRNA <- as.data.frame(lapply( encodedTestSeqsRNA, as.double ))
df_EncodedTestSeqsRNA$y = as.factor(df_EncodedTestSeqsRNA$y)

###############################################################################
# send the test data to the trained model
###############################################################################

yPredMiR2_data1<-predict(bestmodMiR2 , df_EncodedTestSeqsRNA)
table(predict = yPredMiR2_data1, truth = df_EncodedTestSeqsRNA$y)


```


Surprisingly, it didn't make that much difference




```{r checkData1}
# TP
nchar(l_tp<-tb_mirna_test_data$sequence[(yPredMiR2_data1 == tb_mirna_test_data$class) & tb_mirna_test_data$class==1])
# TN
nchar(tb_mirna_test_data$sequence[(yPredMiR2_data1 == tb_mirna_test_data$class) & tb_mirna_test_data$class==0])
# FP
nchar(tb_mirna_test_data$sequence[(yPredMiR2_data1 != tb_mirna_test_data$class) & tb_mirna_test_data$class==0])
#true_positives_indices <- which(yPredMiR_2 == positive_class_label & class == positive_class_label)
# FN 
nchar(tb_mirna_test_data$sequence[(yPredMiR2_data1 != tb_mirna_test_data$class) & tb_mirna_test_data$class==1])
tb_mirna_test_data__fn<-tb_mirna_test_data[(yPredMiR2_data1 != tb_mirna_test_data$class) & tb_mirna_test_data$class==1,]
p<-ggplot(data = tb_mirna_test_data__fn, aes(x = str_length(sequence))) +
     geom_histogram(binwidth = 1, fill = "red", color = "blue") +
     scale_x_continuous(breaks = seq(15, 30, by = 1)) +
     labs(x = "miRNA length", y="count", title = "Distribution of miRNA lengths",
    subtitle = "for False Positives in test dataset 1")
```

## Test Data 2

The second dataset is another set of 22nt 25 human miRNAs and a set of 25 piRNAs that have been trimmed down to 22nt from the 3' end. 

```{r testMiRModel2}

mirna_prediction_test_data_path_2<-here(rootFolder, mirna_prediction_folder, mirna_prediction_test_data_2)

###############################################################################
# load the file
###############################################################################
tryCatch(
  expr = { 
    mirsvm_logger$info(sprintf("loading miRNA  test data from <%s>", mirna_prediction_test_data_path_2))
    tb_mirna_test_data_2<-read_tsv(mirna_prediction_test_data_path_2)
    },
  warning = function(w) { mirsvm_logger$warn(sprintf("got warning %s...", w)) },
  error = function(e) { 
    mirsvm_logger$error(sprintf("got error %s...", e))
    rlang::abort("Aborting: couldn't load test data 2.") },# Code to execute if an error occurs 
  finally = { }# Code to execute regardless of errors or warnings
)



encodedTestSeqsDNA_2<-data.frame(do.call(rbind,lapply(tb_mirna_test_data_2$sequence, one_hot_encode)))

# add classification column
y<-tb_mirna_test_data_2$class
encodedTestSeqsDNA_2  <-cbind(y,encodedTestSeqsDNA_2)

# persuade a list of strings to become a dataframe of doubles
df_encodedTestSeqsDNA_2 <- as.data.frame(lapply( encodedTestSeqsDNA_2, as.double ))
df_encodedTestSeqsDNA_2$y = as.factor(df_encodedTestSeqsDNA_2$y)

yPredMiR_2<-predict(bestmodMiR2 , df_encodedTestSeqsDNA_2)
table(predict = yPredMiR_2 , truth = df_encodedTestSeqsDNA_2$y)

```

```{r inspectResults}


# TP
tb_mirna_test_data_2$name[(yPredMiR_2 == tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==1]
# TN
tb_mirna_test_data_2$name[(yPredMiR_2 == tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==0]
# FP
tb_mirna_test_data_2$name[(yPredMiR_2 != tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==0]
#true_positives_indices <- which(yPredMiR_2 == positive_class_label & class == positive_class_label)
# FN 
tb_mirna_test_data_2$name[(yPredMiR_2 != tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==1]


# TP
nchar(l_tp<-tb_mirna_test_data_2$sequence[(yPredMiR_2 == tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==1])
# TN
nchar(tb_mirna_test_data_2$sequence[(yPredMiR_2 == tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==0])
# FP
nchar(tb_mirna_test_data_2$sequence[(yPredMiR_2 != tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==0])
#true_positives_indices <- which(yPredMiR_2 == positive_class_label & class == positive_class_label)
# FN 
nchar(tb_mirna_test_data_2$sequence[(yPredMiR_2 != tb_mirna_test_data_2$class) & tb_mirna_test_data_2$class==1])
```

The model performance is even worse. So, the model is better at discrimating between miRNAs and random sequence, than between piRNAs and miRNAs. 


## Trying different kernel with dataset 1

```{r trainMiRs_radial}
library(e1071)
#svmfitMiR2=svm(y~., data=dfEncodedTrainSeqsRNA, kernel="radial", cost=0.1,scale=FALSE)
#bestmodMiRR <- tunedMiRR$best.model
bestmodMiRR<-readRDS(here(rootFolder, mirna_prediction_folder, "data", "bestmodMiRR.rds"))
summary(bestmodMiRR)

# it takes a while to run the training, so we save the trained model

saveRDS(tunedMiRR, file = here(rootFolder, mirna_prediction_folder, "data", "tunedMiRR.rds"))
saveRDS(bestmodMiRR, file = here(rootFolder, mirna_prediction_folder, "data", "bestmodMiRR.rds"))

yPredMiRR_data1<-predict(bestmodMiRR , df_EncodedTestSeqsRNA)
table(predict = yPredMiRR_data1, truth = df_EncodedTestSeqsRNA$y)

``` 

## Creating a new training set with matched lengths

Let's see what happens if we generate a set of random sequences that have the same length distribution as the positive miRNAs sequences

To do this, we have to 

  1. Get the number of sequences of each length in the set of positive sequences

  2. Create a function that generates a specific number of random sequences for a specified sequence length

```{r generateBalancedTrainingData}
###############################################################################
# Task 1
#   we can get the lengths of sequences from the histogram we generated 
#   for the positive training data as follows
###############################################################################
p<-ggplot(data = tb_mirna_pos_data , aes(x = str_length(sequence))) +
     geom_histogram(binwidth = 1, fill = "green", color = "black") +
     scale_x_continuous(breaks = seq(15, 30, by = 1)) +
     labs(x = "miRNA length", y="count", title = "Distribution of miRNA lengths",
    subtitle = "for positive training data")


build_data <- ggplot_build(p)

histogram_counts <- build_data$data[[1]]$count
bin_boundaries <- rowMeans(build_data$data[[1]][c("xmin", "xmax")])

# make a tibble of these data
tb_training_data__hist_data<-tibble(seq_lens = bin_boundaries, seq_counts = histogram_counts)

###############################################################################
# create a function to call the Biostrings::create_sequences() method
###############################################################################
gen_rand_seq <- function(num_seqs, seq_len) {
  return(create_sequences(seqnum = num_seqs, 
                          seqlen = seq_len,
         alphabet = "RNA",
         freqs = c(A = 0.25, U = 0.25, C = 0.25, G = 0.25)))
}

###############################################################################
# iterate over the tibble of histogram counts, generate random sequences
# for the sequence length and sequence count and append to a 
# Biostrings::RNAStringSet() object
###############################################################################
balanced_random_seqs <- RNAStringSet()
for (i in 1:nrow(tb_training_data__hist_data)) {
  seq_len <- tb_training_data__hist_data$seq_lens[i]
  seq_counts <- tb_training_data__hist_data$seq_counts[i]
  x<-gen_rand_seq(seq_counts, seq_len)
  balanced_random_seqs<-append(balanced_random_seqs, x)

}

###############################################################################
# create a tibble as above
###############################################################################
tb_balanced_neg_data<-as_tibble(list(name = paste0("random_", 1:1500),
                        sequence = as.character(RNAStringSet(balanced_random_seqs)),
                        class = rep(0,1500)))

###############################################################################
# and generate histograms of sequence lengths for positive and negative data 
###############################################################################
library(cowplot)
p_pos<-ggplot(data = tb_mirna_pos_data, aes(x = str_length(sequence))) +
     geom_histogram(binwidth = 1, fill = "green", color = "blue") +
     scale_x_continuous(breaks = seq(15, 30, by = 1)) +
     labs(x = "miRNA length", y="count", title = "Distribution of miRNA lengths",
    subtitle = "for +VE sequences in balanced training dataset")

p_neg<-ggplot(data = tb_balanced_neg_data, aes(x = str_length(sequence))) +
     geom_histogram(binwidth = 1, fill = "red", color = "blue") +
     scale_x_continuous(breaks = seq(15, 30, by = 1)) +
     labs(x = "miRNA length", y="count", title = "Distribution of miRNA lengths",
    subtitle = "for -VE sequences in balanced training dataset")
p_pn<-plot_grid(p_pos, p_neg, ncol = 2)

tb_mirna_balanced_train_data_all<-bind_rows(tb_mirna_pos_data, tb_balanced_neg_data)

# one hotencode
encodedBalancedTrainSeqsRNA<-data.frame(do.call(rbind,lapply(tb_mirna_balanced_train_data_all$sequence, one_hot_encode_RNA)))

# add classification column
y<-tb_mirna_balanced_train_data_all$class
encodedBalancedTrainSeqsRNA  <-cbind(y, encodedBalancedTrainSeqsRNA)

# persuade a list of strings to become a dataframe of doubles
dfEncodedBalancedTrainSeqsRNA <- as.data.frame(lapply(encodedBalancedTrainSeqsRNA, as.double ))
dfEncodedBalancedTrainSeqsRNA$y = as.factor(dfEncodedBalancedTrainSeqsRNA$y)
```

## training new SVMs with a balanced dataset

### SVM polynomial

First of all we train a SVM with a `polynomial` kernel

```{r trainSVMPoly_balancedData}

library(e1071)


#svmfitMiR$index
bestmodMiR_balanced_poly<-readRDS(here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR_balanced_poly.rds"))
#tunedMiR_balanced_poly <- tune(svm , y~.,  
#                          data = dfEncodedBalancedTrainSeqsRNA , 
#                          kernel = "polynomial", 
#                          ranges = list(cost = c(0.001 , 0.01, 0.1, 1, 5, 10, 100)))
#summary(tunedMiR_balanced_poly)

#bestmodMiR_balanced_poly <- tunedMiR_balanced_poly$best.model
summary(bestmodMiR_balanced_poly)

# it takes a while to run the training, so we save the trained model

saveRDS(tunedMiR_balanced_poly, file = here(rootFolder, mirna_prediction_folder, "data", "tunedMiR_balanced_poly.rds"))
saveRDS(bestmodMiR_balanced_poly, file = here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR_balanced_poly.rds"))
```

And test against test dataset 1

```{r testSVMPolyBalanced_vs_data1}
###############################################################################
# send the test data to the trained model
###############################################################################

yPredMiR_balanced_poly<-predict(bestmodMiR_balanced_poly , df_EncodedTestSeqsRNA)
table(predict = yPredMiR_balanced_poly , truth = df_EncodedTestSeqsRNA$y)

```


### SVM polynomial

Next train a SVM with a `radial`` kernel


```{r trainSVMPoly_balancedData}
bestmodMiR_balanced_radial.rds<-readRDS(here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR_balanced_radial.rds"))
#tunedMiR_balanced_radial <- tune(svm , y~.,  
#                          data = dfEncodedBalancedTrainSeqsRNA , 
#                          kernel = "radial", 
#                          ranges = list(cost = c(0.001 , 0.01, 0.1, 1, 5, 10, 100)))
#summary(tunedMiR_balanced_radial)

#bestmodMiR_balanced_radial <- tunedMiR_balanced_radial$best.model
summary(bestmodMiR_balanced_radial)

#saveRDS(tunedMiR_balanced_radial, file = here(rootFolder, mirna_prediction_folder, "data", "tunedMiR_balanced_radial.rds"))
#saveRDS(bestmodMiR_balanced_radial, file = here(rootFolder, mirna_prediction_folder, "data", "bestmodMiR_balanced_radial.rds"))


yPredMiR_balanced_radial<-predict(bestmodMiR_balanced_radial , df_EncodedTestSeqsRNA)
table(predict = yPredMiR_balanced_radial , truth = df_EncodedTestSeqsRNA$y)
```

# Conclusions

What do you think is happening to explain these results?

